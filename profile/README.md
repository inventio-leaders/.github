# Рекомендательный сервис прогнозирования технологических ситуаций

> Рекурсивная LSTM-модель для прогноза потребления и выявления аномалий (утечек) в системе ГВС/ХВС.


<p align="center">
  <!-- Замените ссылки на свои -->
  <a href="#"><img alt="build" src="https://img.shields.io/badge/build-passing-brightgreen"></a>
  <a href="#"><img alt="tests" src="https://img.shields.io/badge/tests-120%20passed-blue"></a>
  <a href="#"><img alt="coverage" src="https://img.shields.io/badge/coverage-87%25-blueviolet"></a>
</p>

---

## Содержание

* [Общее описание](#общее-описание)
* [Ключевые возможности](#ключевые-возможности)
* [Преимущества](#преимущества)
* [Архитектура и модели](#архитектура-и-модели)
* [API](#api)
* [Быстрый старт](#быстрый-старт)
* [Данные и подготовка](#данные-и-подготовка)
* [Импорт и обработка Excel](#импорт-и-обработка-excel)
* [Дедупликация и загрузка](#дедупликация-и-загрузка)
* [Ошибки и валидация](#ошибки-и-валидация)
* [Типовые сценарии использования](#типовые-сценарии-использования)
* [Прогноз и аномалии](#прогноз-и-аномалии)
* [Метрики и результаты](#метрики-и-результаты)
* [Обратная связь и переобучение](#обратная-связь-и-переобучение)
* [RBAC и роли](#rbac-и-роли)
* [Безопасность и соответствие](#безопасность-и-соответствие)
* [Производительность и SLA](#производительность-и-sla)
* [FAQ](#faq)
* [Авторы и контакты](#авторы-и-контакты)
* [Схемы](#схемы)


---

## Общее описание

Сервис разработан в рамках технического задания АО «Мосводоканал» на хакатон «Лидеры цифровой трансформации 2025» и предназначен для **раннего выявления аномалий**, **прогнозирования рисков** и **снижения социально-экономических последствий** аварийных ситуаций в системе горячего и холодного водоснабжения. Основная цель — обеспечить устойчивость инфраструктуры за счёт цифровой обработки оперативных и исторических данных, поступающих с узлов учёта (ОДПУ ГВС и водосчётчика ХВС в ИТП).

### Ключевые возможности

* **Раннее выявление аномалий**: утечки, неисправности счётчиков, бездоговорное потребление.
* **Прогнозирование рисков**: учёт сезонности, изменения потребления, внешних факторов.
* **Снижение последствий**: предиктивная диагностика, рекомендации по вмешательству, минимизация простоев и потерь воды.

---

## Преимущества  

- **User-friendly interface** — понятный интерфейс, удобная работа с таблицами и визуализациями.  
- **Быстродействие** — высокая скорость обработки Excel-файлов и загрузки больших массивов данных.  
- **Прогнозирование** — автоматический почасовой прогноз потребления ГВС с помощью ML-модели.  
- **Выявление аномалий** — поиск отклонений в исторических данных с указанием уровня серьёзности.  
- **Надёжность** — система обрабатывает ошибки (недостаток данных, некорректные файлы) и сохраняет целостность базы.  

---

## Архитектура и модели

Сервис основан на глубоком обучении и включает два независимых, но взаимодополняющих модуля.

### 1) Прогнозирование расхода ГВС — NARX‑LSTM

**NARX (Nonlinear Autoregressive with eXogenous inputs)** учитывает:

* прошлые значения расхода ГВС;
* экзогенные переменные: расход ХВС, температуру наружного воздуха, час/день недели.

**Выход:** прогноз объёма ГВС на 1–24 часа.
**Точность:** `MAE ≈ 0.05 м³/час` при почасовой дискретности.

### 2) Детекция аномалий — LSTM‑Autoencoder

**Принцип:** модель обучается на «нормальных» данных и восстанавливает входной сигнал.

**Ключевой признак:**

```
Отклонение_% = (|’ХВС_ИТП’ - ‘ГВС_ОДПУ’|/ (('ХВС_ИТП' + 'ГВС_ОДПУ' / 2)) * 100
```

 `'Отклонение_%'` больше 10% становится аномалией.

### 3) Итеративная обратная связь

Оператор может подтвердить или опровергнуть аномалию в интерфейсе; подтверждения используются для дообучения.

---

## API

* **Технология:** FastAPI

# Аутентификация и пользователи

* POST /auth/jwt/login — Auth:Jwt.Login
* POST /auth/jwt/logout — Auth:Jwt.Logout *(требует токен)*
* POST /auth/register — Register

### Пользователи по id (для админ/суперпользователей):

* GET /{id} — Users:User *(требует токен)*
* PATCH /{id} — Users:Patch User *(требует токен)*
* DELETE /{id} — Users:Delete User *(требует токен)*

### Обработанные данные (processed-data)

* GET /processed-data/ — Список
* POST /processed-data/ — Создать
* GET /processed-data/count — Количество
* GET /processed-data/{record_id} — Получить
* PATCH /processed-data/{record_id} — Обновить
* DELETE /processed-data/{record_id} — Удалить
* GET /processed-data/export-xlsx — Экспорт в XLSX
* POST /processed-data/import-excel — Импорт из Excel (multipart)

### Модели (models)

* GET /models/ — Список
* GET /models/count — Количество
* GET /models/{model_id} — Получить

### Прогнозы (forecasts)

* GET /forecasts/ — Список
* POST /forecasts/ — Создать
* GET /forecasts/count — Количество
* GET /forecasts/{forecast_id} — Получить
* PATCH /forecasts/{forecast_id} — Обновить
* DELETE /forecasts/{forecast_id} — Удалить

### Аномалии (anomalies)

* GET /anomalies/ — Список
* POST /anomalies/ — Создать
* GET /anomalies/count — Количество
* GET /anomalies/{anomaly_id} — Получить
* PATCH /anomalies/{anomaly_id} — Обновить
* DELETE /anomalies/{anomaly_id} — Удалить

### ML-задачи

* POST /ml/train — Запуск обучения
* POST /ml/forecast/run — Запуск расчёта прогноза
* POST /ml/anomaly/scan — Скан аномалий
* GET /ml/tasks/{task_id} — Статус задачи

> Подробная спецификация —  `/docs`.

---

## Быстрый старт

### Установка

```bash
git clone https://github.com/inventio-leaders/backend_lct.git
cd backend_lct
```

### Docker (Убедитесь, что вы установили Docker)

```bash
docker-compose up --build
```

---

# Данные и подготовка

### Ожидаемые файлы (Excel → `data/raw/`)

* `Посуточная ведомость водосчетчика ХВС ИТП.xlsx`
* `Посуточная ведомость ОДПУ ГВС.xlsx`
* Убедитесь, что вы вводите дату 3 апреля 2024 года!

## Модель данных `ProcessedData` (ключевые поля)

| Поле              | Тип        | Ед./точность   | Описание                             |
| ----------------- | ---------- | -------------- | ------------------------------------ |
| `record_id`       | int (PK)   | —              | Идентификатор записи                 |
| `datetime`        | `datetime` | UTC/локальное* | Метка периода (час начала интервала) |
| `hour`            | int        | 0–23           | Извлечённый час                      |
| `day_of_week`     | int        | 0–6 (Пн=0)     | День недели                          |
| `is_weekend`      | bool       | —              | Признак выходного (Сб/Вс)            |
| `consumption_gvs` | Decimal    | м³, шаг 0.001  | Потребление ГВС за период            |
| `consumption_hvs` | Decimal    | м³, шаг 0.001  | Потребление ХВС за период            |
| `delta_gvs_hvs`   | Decimal    | м³, шаг 0.001  | `ГВС − ХВС`                          |
| `temp_gvs_supply` | Decimal    | °C, шаг 0.01   | Т1 (подача)                          |
| `temp_gvs_return` | Decimal    | °C, шаг 0.01   | Т2 (обратка)                         |
| `temp_delta`      | Decimal    | °C, шаг 0.01   | `Т1 − Т2`                            |

* Рекомендуется унифицировать часовой пояс (например, хранить в UTC) и задать соответствующий индекс/уникальность.


## Импорт и обработка Excel

Поддерживаются листы двух типов (определяются по заголовкам):

**ГВС (требуемые колонки)**
`{"Дата","Время суток, ч","Подача, м3","Обратка, м3","Потребление за период, м3","Т1 гвс, оС","Т2 гвс, оС"}`

**ХВС (минимально требуемые колонки)**
`{"Дата","Время суток, ч","Потребление за период, м3"}`

Не соответствующие листы пропускаются. Если ни один лист не подошёл — `ValueError`.

  * ГВС:

    * `"Подача, м3" → gvs_supply_m3`
    * `"Обратка, м3" → gvs_return_m3`
    * `"Потребление за период, м3" → gvs_consumption_m3`
    * `"Т1 гвс, оС" → t1_supply`
    * `"Т2 гвс, оС" → t2_return`
  * ХВС:

    * `"Потребление за период, м3" → hvs_consumption_m3`
* Объединение: `outer merge` по `["datetime","hour"]` c `validate="one_to_one"`, сортировка по времени.
* Обогащение признаков:

  * `day_of_week = datetime.weekday()`
  * `is_weekend = day_of_week in {5,6}`
  * Пропуски в числовых полях заполняются нулями.
  * `temp_delta = t1_supply - t2_return`
  * `delta_gvs_hvs = gvs_consumption_m3 - hvs_consumption_m3`
* Финальное переименование под модель:

  * `gvs_consumption_m3 → consumption_gvs`
  * `hvs_consumption_m3 → consumption_hvs`
  * `t1_supply → temp_gvs_supply`
  * `t2_return → temp_gvs_return`

# Дедупликация и загрузка 

* Ключ дедупликации: `datetime` (при включённом `dedupe=True`).
* Алгоритм:

  1. Разбивка собранных записей на чанки по 1000.
  2. Для каждого чанка — выборка существующих `datetime` из БД, сбор в множество `existing_set`.
  3. Фильтрация `records` от уже существующих `datetime`.
     `skipped_existing = total_rows - len(new_records)`.
  4. Массовая вставка по 1000 записей в транзакции; при исключении — `rollback`, затем повторное возбуждение исключения.
* Возвращаемые счётчики: `total_rows`, `inserted`, `skipped_existing`.

## Ошибки и валидация

* Отсутствие обязательных колонок по шаблону — `ValueError` с указанием списка недостающих полей.
* Невалидные дата/час — `ValueError` с пояснением.
* Неверный формат файла — `ValueError("Поддерживаются только .xlsx ...")` или сообщение драйвера `openpyxl`.
* При ошибке вставки в БД — откат транзакции и проброс исключения.

## Типовые сценарии использования

* **Список с фильтрами**:
  Передать `dt_from`, `dt_to`, `hour`, `day_of_week`, `is_weekend`, задать пагинацию `limit/offset`. Получить `(items, total)` для фронтенда (таблица + постраничная навигация).
* **Импорт .xlsx**:
  Передать список загруженных файлов (один или несколько, допускается смешение ГВС/ХВС), опционально `dedupe=True`. Получить сводку вставки.

### Пример результатов `import_processed_data_from_excels`

```json
{
  "inserted": 8640,
  "skipped_existing": 0,
  "total_rows": 8640
}
```

# Тестирование (кратко)

* Позитивные кейсы:

  * Корректные листы ГВС/ХВС по отдельности и вместе; проверка расчётов `temp_delta`, `delta_gvs_hvs`, `is_weekend`.
* Негативные кейсы:

  * Отсутствуют обязательные колонки; некорректные значения `Дата`/`Время суток, ч`; не-xlsx файлы; пересекающиеся `datetime` с `dedupe=True/False`.
* Нагрузочные:

  * Импорт ≥100k строк; оценка времени вставки и потребления памяти.

### Прогноз и аномалии

Прогноз (forecast_job)
Берёт последние W часов данных из таблицы.
Грузит обученную модель прогноза.
Шаг за шагом предсказывает потребление ГВС на каждый следующий час.
Для каждого прогноза создаёт запись в базе с меткой времени (через 1 час, 2 часа и т. д.).
Если данных меньше, чем нужно, прогноз не запускается.

Аномалии (anomaly_scan_job)
Берёт данные за указанный промежуток времени. Если данных мало — достаёт ещё строки «до» этого интервала.
Использует модель-автоэнкодер, чтобы проверить, насколько хорошо данные «вписываются» в нормальный профиль.
Считает ошибку. Если ошибка выше порога, то строка помечается как аномалия.
Для каждой аномалии создаётся запись в базе с датой, уровнем отклонения и порогом.
В итоге фиксируются только те часы, где модель нашла отклонения.

Итог

Первая задача — строит прогноз потребления на будущее.

Вторая задача — отмечает аномальные ситуации в прошедших данных.
---

## Метрики и результаты

| Модуль              | Метрика                      | Значение     |
| ------------------- | ---------------------------- | ------------ |
| NARX‑LSTM (прогноз) | MAE                          | ~0.05 м³/час |
|                     | MAPE                         | < 3%         |
| LSTM‑AE (аномалии)  | Recall (на тестовых утечках) | 92%          |
|                     | False Alarm Rate             | < 5%         |
|                     | Время обнаружения            | < 2 часов    |

---

## Обратная связь и переобучение

* Оператор просматривает аномалию в интерфейсе.

  
  * объединяет исторические и новые данные;
  * дообучает LSTM‑AE с повышенным весом подтверждённых кейсов;
  * обновляет порог аномалии;
  * заменяет модель в прод.

---

## RBAC и роли

> Базируется на модели ролей проекта.

**Роли:**

* **Диспетчер** — просмотр дашбордов, подтверждение/отклонение аномалий.
* **Старший диспетчер** — всё из «Диспетчер» + запуск ручного анализа, экспорт отчётов, **право переобучать модель**.
* **Администратор** — управление конфигурацией/доступами/моделями, **право переобучать модель**.
---

## Безопасность и соответствие

* Соответствие ФЗ‑152; персональные данные **не обрабатываются**.
* RBAC, аудит операций, иммутабельные артефакты моделей.
* Секреты только через `.env`/Secret Manager; без жёстко закодированных ключей.

---

## Производительность и SLA

* **SLA:** отчёт ≤10 сек (MVP: < 3 сек на сегмент).
* **Нагрузка:** до 500 rps.

---
# FAQ  

**Q:** Что будет, если данных за последние часы меньше, чем нужно модели?  
**A:** Прогноз или поиск аномалий не запустятся — система сообщит, что данных недостаточно.  

**Q:** Как понять, что прогноз «хороший»?  
**A:** Сравнивайте предсказанное значение с фактическим потреблением после выгрузки новых данных. Если расхождение в пределах нормы — модель работает корректно.  

**Q:** Что происходит, если модель «ошиблась» и показала отрицательное потребление?  
**A:** Такие значения автоматически обрезаются до нуля.  

**Q:** По какому признаку решается, что есть аномалия?  
**A:** Считается ошибка восстановления (MSE). Если она выше порогового значения — запись помечается как аномалия.  

**Q:** Можно ли изменить этот порог?  
**A:** Да. Он хранится в параметрах модели и может быть обновлён при переобучении. Если порог не задан, используется значение по умолчанию (0.02).  

**Q:** Что делать, если аномалий слишком много?  
**A:** Проверить настройки порога и качество исходных данных. При необходимости — обучить модель заново.  

**Q:** Как проверять, что аномалия «реальная»?  
**A:** Сравните рост показателя `Delta_GVS_HVS` с неизменным расходом ХВС и данными операторов.  

**Q:** Прогноз и аномалии работают отдельно или вместе?  
**A:** Это разные задачи: прогноз смотрит вперёд, аномалия анализирует прошлые данные.  

---

# Авторы и контакты

## Команда разработки «Inventio»  

- **Вячеслав Чучманов** — Fullstack Developer  
  Telegram: [@oliceglad](https://t.me/oliceglad)  

- **Коновалов Павел** — Backend Developer / Delivery Manager  
  Telegram: [@mbalance](https://t.me/mbalance)  

- **Руслан Курбанов** — Web Designer  
  Telegram: [@bondrman](https://t.me/bondrman)  

- **Алена Гриднева** — ML Developer / Mathematician  
  Telegram: [@alyono](https://t.me/alyono)  

- **Егор Поляков** — ML Developer  
  Telegram: [@az_Walker](https://t.me/az_Walker)  

# Схемы  

<p align="center">
  <img src="https://github.com/user-attachments/assets/38959703-6425-4bbe-8485-fdb612c44566" alt="ER схема" width="400"/><br/>
  <em>Рисунок 1. ER схема системы</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/6e5d19a7-2ab7-46ba-b5b3-3b3b6ef8fae1" alt="UML схема" width="800"/><br/>
  <em>Рисунок 2. UML</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/1d1bea93-4a91-42da-bbcb-c56aed14b366" alt="DFD Layer 1" width="800"/><br/>
  <em>Рисунок 3. DFD слой 1</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/0c284bbb-d0bf-4258-a4e1-20056f9a1aeb" alt="DFD Detalisation" width="800"/><br/>
  <em>Рисунок 4. DFD детализация</em>
</p>



